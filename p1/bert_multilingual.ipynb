{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrtc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "from toolz.functoolz import pipe\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForMaskedLM,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from torch.utils.data import (\n",
    "    TensorDataset,\n",
    "    DataLoader,\n",
    "    RandomSampler,\n",
    "    SequentialSampler,\n",
    "    random_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added af-ZA.jsonl to dataframe\n",
      "Added am-ET.jsonl to dataframe\n",
      "Added ar-SA.jsonl to dataframe\n",
      "Added az-AZ.jsonl to dataframe\n",
      "Added bn-BD.jsonl to dataframe\n",
      "Added cy-GB.jsonl to dataframe\n",
      "Added da-DK.jsonl to dataframe\n",
      "Added de-DE.jsonl to dataframe\n",
      "Added el-GR.jsonl to dataframe\n",
      "Added en-US.jsonl to dataframe\n",
      "Added es-ES.jsonl to dataframe\n",
      "Added fa-IR.jsonl to dataframe\n",
      "Added fi-FI.jsonl to dataframe\n",
      "Added fr-FR.jsonl to dataframe\n",
      "Added he-IL.jsonl to dataframe\n",
      "Added hi-IN.jsonl to dataframe\n",
      "Added hu-HU.jsonl to dataframe\n",
      "Added hy-AM.jsonl to dataframe\n",
      "Added id-ID.jsonl to dataframe\n",
      "Added is-IS.jsonl to dataframe\n",
      "Added it-IT.jsonl to dataframe\n",
      "Added ja-JP.jsonl to dataframe\n",
      "Added jv-ID.jsonl to dataframe\n",
      "Added ka-GE.jsonl to dataframe\n",
      "Added km-KH.jsonl to dataframe\n",
      "Added kn-IN.jsonl to dataframe\n",
      "Added ko-KR.jsonl to dataframe\n",
      "Added lv-LV.jsonl to dataframe\n",
      "Added ml-IN.jsonl to dataframe\n",
      "Added mn-MN.jsonl to dataframe\n",
      "Added ms-MY.jsonl to dataframe\n",
      "Added my-MM.jsonl to dataframe\n",
      "Added nb-NO.jsonl to dataframe\n",
      "Added nl-NL.jsonl to dataframe\n",
      "Added pl-PL.jsonl to dataframe\n",
      "Added pt-PT.jsonl to dataframe\n",
      "Added ro-RO.jsonl to dataframe\n",
      "Added ru-RU.jsonl to dataframe\n",
      "Added sl-SL.jsonl to dataframe\n",
      "Added sq-AL.jsonl to dataframe\n",
      "Added sv-SE.jsonl to dataframe\n",
      "Added sw-KE.jsonl to dataframe\n",
      "Added ta-IN.jsonl to dataframe\n",
      "Added te-IN.jsonl to dataframe\n",
      "Added th-TH.jsonl to dataframe\n",
      "Added tl-PH.jsonl to dataframe\n",
      "Added tr-TR.jsonl to dataframe\n",
      "Added ur-PK.jsonl to dataframe\n",
      "Added vi-VN.jsonl to dataframe\n",
      "Added zh-CN.jsonl to dataframe\n",
      "Added zh-TW.jsonl to dataframe\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for json_file in os.listdir(\"dataset/jsonl\"):\n",
    "    df = pd.concat(\n",
    "        [df, pd.read_json(\"dataset/jsonl/\" + json_file, lines=True)], ignore_index=True\n",
    "    )\n",
    "    print(f\"Added {json_file} to dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"preprocess_nolang.ipynb\"\n",
    "%run -i \"evaluation.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing dataset.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"locale\"] = df[\"locale\"].apply(lambda x: x.split(\"-\")[0])\n",
    "\n",
    "params = [\n",
    "    remove_punctuation,\n",
    "    drop_cols,\n",
    "    lowercase,\n",
    "]\n",
    "\n",
    "\n",
    "df = pipe(df, *params)\n",
    "\n",
    "\n",
    "df, encoder = encode_labels(df)\n",
    "\n",
    "print(f\"Finished preprocessing dataset.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = df[\"utt\"].values\n",
    "labels = df[\"intent\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 615/615 [00:00<00:00, 308kB/s]\n",
      "Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:01<00:00, 2.93MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 9.10M/9.10M [00:04<00:00, 2.03MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.12G/1.12G [01:34<00:00, 11.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  maak my wakker om vyf v m die week\n",
      "Tokenized:  ['▁maak', '▁my', '▁wa', 'kker', '▁om', '▁vyf', '▁v', '▁m', '▁die', '▁week']\n",
      "Token IDs:  [7129, 759, 259, 6850, 171, 114995, 81, 347, 68, 5895]\n"
     ]
    }
   ],
   "source": [
    "print(\"Original: \", utterances[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print(\"Tokenized: \", tokenizer.tokenize(utterances[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print(\"Token IDs: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(utterances[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  210\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "for sent in utterances:\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print(\"Max sentence length: \", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrtc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for utt in utterances:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        utt,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_dict[\"input_ids\"])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict[\"attention_mask\"])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print(\"Original: \", utterances[0])\n",
    "print(\"Token IDs:\", input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 80-20 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.8 * len(dataset))\n",
    "# val_size = int(0.2 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(\"{:>5,} training samples\".format(train_size))\n",
    "print(\"{:>5,} validation samples\".format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=2e-5,\n",
    "    eps=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    \"\"\"\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    \"\"\"\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"======== Epoch {epoch} / {epochs} ========\")\n",
    "    print(\"Training...\")\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        output = model(\n",
    "            b_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels,\n",
    "        )\n",
    "\n",
    "        loss = output.loss\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            output = model(\n",
    "                b_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "\n",
    "            loss = output.loss\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, \"bert_model\")\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"Training Loss\": avg_train_loss,\n",
    "            \"Valid. Loss\": avg_val_loss,\n",
    "            \"Valid. Accur.\": avg_val_accuracy,\n",
    "            \"Training Time\": training_time,\n",
    "            \"Validation Time\": validation_time,\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
