{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torcheval torchmetrics\nimport numpy as np\nimport pandas as pd\nimport os \nimport torch\nimport random\nimport time\nfrom torch.utils.data import TensorDataset, DataLoader, SequentialSampler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score\nfrom transformers import get_linear_schedule_with_warmup\nfrom torcheval.metrics.functional import multiclass_accuracy, multiclass_f1_score\nfrom tqdm.notebook import tqdm\nimport json\nimport torchmetrics\nfrom torchmetrics.classification import MulticlassAccuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:48:23.417004Z","iopub.execute_input":"2023-05-25T19:48:23.417392Z","iopub.status.idle":"2023-05-25T19:48:49.576961Z","shell.execute_reply.started":"2023-05-25T19:48:23.417361Z","shell.execute_reply":"2023-05-25T19:48:49.575958Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torcheval\n  Downloading torcheval-0.0.6-py3-none-any.whl (158 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.4/158.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (0.11.4)\nCollecting torchtnt>=0.0.5 (from torcheval)\n  Downloading torchtnt-0.1.0-py3-none-any.whl (87 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.5.0)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.23.5)\nRequirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (2023.5.0)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (2.12.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (5.9.3)\nCollecting pyre-extensions (from torchtnt>=0.0.5->torcheval)\n  Downloading pyre_extensions-0.0.30-py3-none-any.whl (12 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (59.8.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (4.64.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->torchmetrics) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\nRequirement already satisfied: typing-inspect in /opt/conda/lib/python3.10/site-packages (from pyre-extensions->torchtnt>=0.0.5->torcheval) (0.8.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.4.3)\nRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.28.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.7.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.3.4)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.40.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.2.7)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (1.16.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2023.5.7)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect->pyre-extensions->torchtnt>=0.0.5->torcheval) (1.0.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (3.2.2)\nInstalling collected packages: pyre-extensions, torchtnt, torcheval\nSuccessfully installed pyre-extensions-0.0.30 torcheval-0.0.6 torchtnt-0.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check if GPU is available to evaluate the model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:48:49.580094Z","iopub.execute_input":"2023-05-25T19:48:49.580743Z","iopub.status.idle":"2023-05-25T19:48:49.651961Z","shell.execute_reply.started":"2023-05-25T19:48:49.580706Z","shell.execute_reply":"2023-05-25T19:48:49.651049Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"# Preprocessing helper functions\ndef remove_punctuation(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Remove punctuation from text\"\"\"\n    data[\"utt\"] = data[\"utt\"].str.replace(r\"[^\\w\\s]\",\"\", regex=True)\n    return data\n\ndef lowercase(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Lowercase text\"\"\"\n    data[\"utt\"] = data[\"utt\"].str.lower()\n    return data\n\ndef drop_cols(data: pd.DataFrame) -> pd.DataFrame:\n    drop = [\"worker_id\", \"slot_method\", \"judgments\"]\n    return data.drop(drop, axis=1)\n\ndef encode_labels(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Encode labels\"\"\"\n    le = LabelEncoder()\n    le.fit(data['intent'])\n    data['intent'] = le.transform(data['intent'])\n    return data, le\n\ndef decode_labels(data: np.ndarray, le: LabelEncoder) -> np.ndarray:\n    \"\"\"Decode labels\"\"\"\n    data = le.inverse_transform(data)\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:48:49.653677Z","iopub.execute_input":"2023-05-25T19:48:49.654445Z","iopub.status.idle":"2023-05-25T19:48:49.665086Z","shell.execute_reply.started":"2023-05-25T19:48:49.654410Z","shell.execute_reply":"2023-05-25T19:48:49.663955Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Assemble the data\ndf = pd.DataFrame()\n\nfor json_file in os.listdir('/kaggle/input/massive-dataset-v1-nlpnlu'):\n    if json_file.endswith('.jsonl'):\n        df = pd.concat([df, pd.read_json('/kaggle/input/massive-dataset-v1-nlpnlu/' + json_file, lines=True)], ignore_index=True)\n        print(f\"Added {json_file} to dataframe\")","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:48:49.668001Z","iopub.execute_input":"2023-05-25T19:48:49.668353Z","iopub.status.idle":"2023-05-25T19:49:24.823682Z","shell.execute_reply.started":"2023-05-25T19:48:49.668323Z","shell.execute_reply":"2023-05-25T19:49:24.822579Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Added ko-KR.jsonl to dataframe\nAdded zh-TW.jsonl to dataframe\nAdded ru-RU.jsonl to dataframe\nAdded th-TH.jsonl to dataframe\nAdded te-IN.jsonl to dataframe\nAdded am-ET.jsonl to dataframe\nAdded jv-ID.jsonl to dataframe\nAdded cy-GB.jsonl to dataframe\nAdded hi-IN.jsonl to dataframe\nAdded fi-FI.jsonl to dataframe\nAdded mn-MN.jsonl to dataframe\nAdded ur-PK.jsonl to dataframe\nAdded km-KH.jsonl to dataframe\nAdded kn-IN.jsonl to dataframe\nAdded sl-SL.jsonl to dataframe\nAdded ro-RO.jsonl to dataframe\nAdded ml-IN.jsonl to dataframe\nAdded he-IL.jsonl to dataframe\nAdded en-US.jsonl to dataframe\nAdded es-ES.jsonl to dataframe\nAdded zh-CN.jsonl to dataframe\nAdded da-DK.jsonl to dataframe\nAdded nl-NL.jsonl to dataframe\nAdded ar-SA.jsonl to dataframe\nAdded sv-SE.jsonl to dataframe\nAdded tl-PH.jsonl to dataframe\nAdded is-IS.jsonl to dataframe\nAdded fr-FR.jsonl to dataframe\nAdded my-MM.jsonl to dataframe\nAdded nb-NO.jsonl to dataframe\nAdded id-ID.jsonl to dataframe\nAdded az-AZ.jsonl to dataframe\nAdded af-ZA.jsonl to dataframe\nAdded fa-IR.jsonl to dataframe\nAdded ta-IN.jsonl to dataframe\nAdded de-DE.jsonl to dataframe\nAdded sq-AL.jsonl to dataframe\nAdded pt-PT.jsonl to dataframe\nAdded hu-HU.jsonl to dataframe\nAdded pl-PL.jsonl to dataframe\nAdded lv-LV.jsonl to dataframe\nAdded ja-JP.jsonl to dataframe\nAdded vi-VN.jsonl to dataframe\nAdded bn-BD.jsonl to dataframe\nAdded sw-KE.jsonl to dataframe\nAdded it-IT.jsonl to dataframe\nAdded el-GR.jsonl to dataframe\nAdded ms-MY.jsonl to dataframe\nAdded hy-AM.jsonl to dataframe\nAdded ka-GE.jsonl to dataframe\nAdded tr-TR.jsonl to dataframe\n","output_type":"stream"}]},{"cell_type":"code","source":"from toolz.functoolz import pipe\n# Preprocess the data using a pipeline\ndf[\"locale\"] = df[\"locale\"].apply(lambda x: x.split(\"-\")[0])\n\nparams = [\n    remove_punctuation,\n    drop_cols,\n    lowercase,\n]\n\ndf = pipe(\n    df,\n    *params\n)\n\ndf, encoder = encode_labels(df)\n\nprint(f\"Finished preprocessing dataset.\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:49:24.828223Z","iopub.execute_input":"2023-05-25T19:49:24.830318Z","iopub.status.idle":"2023-05-25T19:49:30.543224Z","shell.execute_reply.started":"2023-05-25T19:49:24.830292Z","shell.execute_reply":"2023-05-25T19:49:30.542183Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Finished preprocessing dataset.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df = df.loc[df['partition'] == 'test']","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:49:30.544574Z","iopub.execute_input":"2023-05-25T19:49:30.545002Z","iopub.status.idle":"2023-05-25T19:49:31.079929Z","shell.execute_reply.started":"2023-05-25T19:49:30.544967Z","shell.execute_reply":"2023-05-25T19:49:31.078988Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"utterances = test_df['utt'].values\nlangs = test_df['locale'].values\nlabels = test_df['intent'].values","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:49:31.081197Z","iopub.execute_input":"2023-05-25T19:49:31.081755Z","iopub.status.idle":"2023-05-25T19:49:31.087865Z","shell.execute_reply.started":"2023-05-25T19:49:31.081707Z","shell.execute_reply":"2023-05-25T19:49:31.086792Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from more_itertools import locate\n\nlang_to_index_list = {}\nfor lang in df['locale'].unique():\n    lang_to_index_list[lang] = list(locate(langs, lambda x: x == lang))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:49:31.089228Z","iopub.execute_input":"2023-05-25T19:49:31.089660Z","iopub.status.idle":"2023-05-25T19:49:32.878003Z","shell.execute_reply.started":"2023-05-25T19:49:31.089624Z","shell.execute_reply":"2023-05-25T19:49:32.877042Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"lang_to_index_list.keys()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:49:32.879275Z","iopub.execute_input":"2023-05-25T19:49:32.880088Z","iopub.status.idle":"2023-05-25T19:49:32.886576Z","shell.execute_reply.started":"2023-05-25T19:49:32.880054Z","shell.execute_reply":"2023-05-25T19:49:32.885614Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"dict_keys(['ko', 'zh', 'ru', 'th', 'te', 'am', 'jv', 'cy', 'hi', 'fi', 'mn', 'ur', 'km', 'kn', 'sl', 'ro', 'ml', 'he', 'en', 'es', 'da', 'nl', 'ar', 'sv', 'tl', 'is', 'fr', 'my', 'nb', 'id', 'az', 'af', 'fa', 'ta', 'de', 'sq', 'pt', 'hu', 'pl', 'lv', 'ja', 'vi', 'bn', 'sw', 'it', 'el', 'ms', 'hy', 'ka', 'tr'])"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(tokenizer):\n    input_ids = []\n    attention_masks = []\n\n    for utt in utterances:\n        # `encode_plus` will:\n        #   (1) Tokenize the sentence.\n        #   (2) Prepend the `[CLS]` token to the start.\n        #   (3) Append the `[SEP]` token to the end.\n        #   (4) Map tokens to their IDs.\n        #   (5) Pad or truncate the sentence to `max_length`\n        #   (6) Create attention masks for [PAD] tokens.\n        encoded_dict = tokenizer.encode_plus(\n                            utt,                      # Sentence to encode.\n                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n                            max_length = 128,           # Pad & truncate all sentences.\n                            truncation = True,\n                            padding = 'max_length',\n                            return_attention_mask = True,   # Construct attn. masks.\n                            return_tensors = 'pt',     # Return pytorch tensors.\n                       )\n\n        # Add the encoded sentence to the list.    \n        input_ids.append(encoded_dict['input_ids'])\n\n        # And its attention mask (simply differentiates padding from non-padding).\n        attention_masks.append(encoded_dict['attention_mask'])\n\n\n    # Convert the lists into tensors.\n    input_ids = torch.cat(input_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0)\n    labels_ = torch.tensor(labels)\n\n    # Print sentence 0, now as a list of IDs.\n    print('Original: ', utterances[0])\n    print('Token IDs:', input_ids[0])\n    return input_ids, attention_masks, labels_","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:49:32.890270Z","iopub.execute_input":"2023-05-25T19:49:32.890864Z","iopub.status.idle":"2023-05-25T19:49:32.899104Z","shell.execute_reply.started":"2023-05-25T19:49:32.890832Z","shell.execute_reply":"2023-05-25T19:49:32.898227Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nmodels = [\"xlm-roberta-base\", \"microsoft/mdeberta-v3-base\"]\n\nmodels_finetuned = {\n    \"xlm-roberta-base\": \"/kaggle/input/models/xlm-roberta-MASSIVE-finetuned\",\n    \"microsoft/mdeberta-v3-base\": \"/kaggle/input/models/mdeberta-MASSIVE-finetuned\"\n}","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:49:32.901148Z","iopub.execute_input":"2023-05-25T19:49:32.902006Z","iopub.status.idle":"2023-05-25T19:49:32.912462Z","shell.execute_reply.started":"2023-05-25T19:49:32.901976Z","shell.execute_reply":"2023-05-25T19:49:32.911688Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def seed_everything():\n    seed_val = 42\n    random.seed(seed_val)\n    np.random.seed(seed_val)\n    torch.manual_seed(seed_val)\n    torch.cuda.manual_seed_all(seed_val)\n    training_stats = []\n    \ndef load_model_tokenizer(idx: int):\n    model = torch.load(models_finetuned[models[idx]])\n    model = model.to(device)\n    tokenizer = AutoTokenizer.from_pretrained(models[idx])\n    return (model, tokenizer)\n\ndef test_model(idx: int):\n    print(\"Seeding...\")\n    seed_everything()\n    print(\"Seeded. Loading model and tokenizer...\")\n    model, tokenizer = load_model_tokenizer(idx)\n    \n    print(\"Loaded. Tokenizing...\")\n    input_ids_, attention_masks_, labels_ = tokenize(tokenizer)\n    \n    print(\"Tokenized. Generating dataloader...\")\n    dataset_ = TensorDataset(input_ids_, attention_masks_, labels_)\n    dataloader = DataLoader(\n            dataset_,\n            sampler = SequentialSampler(dataset_),\n            batch_size = 32)\n    \n    # Put in eval mode so weird things don't happen\n    model.eval()\n    \n    metrics = {}\n    print(\"Starting prediction\")\n    # Testing the data in batches\n    batches_tqdm = tqdm(enumerate(dataloader), desc=f\"Evaluation {models[idx]}\", total=len(dataloader))\n    \n    metric = MulticlassAccuracy(num_classes=60).to(device)\n    preds = np.array([])\n    targets = np.array([])\n\n    for _, batch in batches_tqdm:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n        # Tell pytorch not to bother with constructing the compute graph during\n        # the forward pass, since this is only needed for backprop (training).\n        with torch.no_grad():\n            output= model(input_ids = b_input_ids, attention_mask = b_input_mask,labels = b_labels)\n\n        logits = output.logits\n        acc = metric(torch.argmax(logits, dim=1), b_labels)        \n        preds = np.append(preds, torch.argmax(logits, dim=1).cpu().numpy())\n        targets = np.append(targets, b_labels.cpu().numpy())\n\n    accuracy = metric.compute()\n    print(f\"Accuracy = {accuracy.item()}\")\n    metrics['all'] = accuracy.item()\n  \n\n    for lang in lang_to_index_list.keys():\n        metric = MulticlassAccuracy(num_classes=60)\n        preds_ = torch.index_select(torch.tensor(preds), 0, torch.LongTensor(lang_to_index_list[lang]))\n        targets_ = torch.index_select(torch.tensor(targets), 0, torch.LongTensor(lang_to_index_list[lang]))\n        acc = metric(preds_, targets_)\n        metrics[lang] = acc.item()\n        print(f\"For language {lang}, acc = {acc.item()}:\\n {preds_}\\n {targets_}\\n\")\n\n    with open(f\"metrics-{models[idx].replace('/','-')}.json\", \"w\") as f:\n        json.dump(metrics, f)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:39:31.636391Z","iopub.execute_input":"2023-05-25T20:39:31.637122Z","iopub.status.idle":"2023-05-25T20:39:31.652780Z","shell.execute_reply.started":"2023-05-25T20:39:31.637088Z","shell.execute_reply":"2023-05-25T20:39:31.651631Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:39:32.219710Z","iopub.execute_input":"2023-05-25T20:39:32.220703Z","iopub.status.idle":"2023-05-25T20:39:32.226901Z","shell.execute_reply.started":"2023-05-25T20:39:32.220643Z","shell.execute_reply":"2023-05-25T20:39:32.225737Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"test_model(1)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:39:32.475009Z","iopub.execute_input":"2023-05-25T20:39:32.475323Z","iopub.status.idle":"2023-05-25T21:00:40.792235Z","shell.execute_reply.started":"2023-05-25T20:39:32.475295Z","shell.execute_reply":"2023-05-25T21:00:40.790988Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Seeding...\nSeeded. Loading model and tokenizer...\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Loaded. Tokenizing...\nOriginal:  이번 주 오전 다섯 시 에 깨워줘\nToken IDs: tensor([[     1,    260,  26229,   3920,   4559,   3228,   3730, 155166,   6464,\n            260,    874,    260,  56580,  11110, 159035,      2,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0]])\nTokenized. Generating dataloader...\nStarting prediction\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluation microsoft/mdeberta-v3-base:   0%|          | 0/4740 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"905cac2e0321469baed0512a85049cec"}},"metadata":{}},{"name":"stdout","text":"Accuracy = 0.8033444285392761\nFor language ko, acc = 0.8336948156356812:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language zh, acc = 0.8262818455696106:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language ru, acc = 0.8587443828582764:\n tensor([ 2.,  3., 46.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language th, acc = 0.766815185546875:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 17.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language te, acc = 0.6881203055381775:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 17.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language am, acc = 0.7904495000839233:\n tensor([ 2.,  4., 30.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language jv, acc = 0.8279184103012085:\n tensor([ 2.,  4., 30.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language cy, acc = 0.7771586775779724:\n tensor([ 7.,  4., 21.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language hi, acc = 0.7611342668533325:\n tensor([ 2., 25., 19.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language fi, acc = 0.8452845215797424:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language mn, acc = 0.8212765455245972:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language ur, acc = 0.8114703893661499:\n tensor([ 2.,  4., 30.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language km, acc = 0.5083578824996948:\n tensor([ 2.,  6., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language kn, acc = 0.6859358549118042:\n tensor([ 2.,  4., 39.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language sl, acc = 0.8204333186149597:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language ro, acc = 0.8329379558563232:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language ml, acc = 0.6939563155174255:\n tensor([ 2.,  3., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language he, acc = 0.8226162195205688:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language en, acc = 0.8798643946647644:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language es, acc = 0.8403192758560181:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language da, acc = 0.8433155417442322:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language nl, acc = 0.848215639591217:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language ar, acc = 0.7959402799606323:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language sv, acc = 0.8490571975708008:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language tl, acc = 0.8100422620773315:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language is, acc = 0.8340776562690735:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language fr, acc = 0.844670832157135:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language my, acc = 0.514378547668457:\n tensor([ 2.,  4.,  7.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language nb, acc = 0.839809238910675:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language id, acc = 0.8592272400856018:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language az, acc = 0.8345025777816772:\n tensor([ 2., 40., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language af, acc = 0.8393716812133789:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language fa, acc = 0.8470839262008667:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language ta, acc = 0.6392015218734741:\n tensor([ 0.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language de, acc = 0.8608254194259644:\n tensor([ 2.,  4., 40.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language sq, acc = 0.8438865542411804:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language pt, acc = 0.837731122970581:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language hu, acc = 0.8441901206970215:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language pl, acc = 0.8515642881393433:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language lv, acc = 0.8640647530555725:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language ja, acc = 0.8350170850753784:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language vi, acc = 0.8214735984802246:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language bn, acc = 0.7100446820259094:\n tensor([ 2.,  4., 31.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language sw, acc = 0.8071987628936768:\n tensor([ 2.,  4., 22.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language it, acc = 0.8560571670532227:\n tensor([ 2.,  4., 40.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language el, acc = 0.8400161266326904:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language ms, acc = 0.846342921257019:\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language hy, acc = 0.8343269228935242:\n tensor([ 2.,  4., 20.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language ka, acc = 0.7786347270011902:\n tensor([ 2.,  4., 11.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\nFor language tr, acc = 0.8212445974349976:\n tensor([ 2.,  4., 30.,  ..., 15., 15., 15.], dtype=torch.float64)\n tensor([ 2.,  4., 23.,  ..., 15., 15., 15.], dtype=torch.float64)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:10:30.575147Z","iopub.status.idle":"2023-05-25T20:10:30.577463Z","shell.execute_reply.started":"2023-05-25T20:10:30.577197Z","shell.execute_reply":"2023-05-25T20:10:30.577222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_stats","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:10:30.578749Z","iopub.status.idle":"2023-05-25T20:10:30.579562Z","shell.execute_reply.started":"2023-05-25T20:10:30.579306Z","shell.execute_reply":"2023-05-25T20:10:30.579329Z"},"trusted":true},"execution_count":null,"outputs":[]}]}