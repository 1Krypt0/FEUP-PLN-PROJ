{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "LANG_MAP = {\n",
    "    \"ar\": \"arabic\",\n",
    "    \"da\": \"danish\",\n",
    "    \"nl\": \"dutch\",\n",
    "    \"en\": \"english\",\n",
    "    \"fi\": \"finnish\",\n",
    "    \"fr\": \"french\",\n",
    "    \"de\": \"german\",\n",
    "    \"hu\": \"hungarian\",\n",
    "    \"it\": \"italian\",\n",
    "    \"nb\": \"norwegian\",\n",
    "    \"pt\": \"portuguese\",\n",
    "    \"ro\": \"romanian\",\n",
    "    \"ru\": \"russian\",\n",
    "    \"es\": \"spanish\",\n",
    "    \"sv\": \"swedish\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_stemmer(locale: str):\n",
    "    \"\"\"\n",
    "    Returns the approprate stemmer, if one exists\n",
    "    \"\"\"\n",
    "    if locale in LANG_MAP:\n",
    "        return SnowballStemmer(LANG_MAP[locale])\n",
    "    return lambda x: x\n",
    "\n",
    "\n",
    "def stem(stemmer, utterance: str) -> str:\n",
    "    \"\"\"\n",
    "    Stems the utterance after tokenizing it\n",
    "    \"\"\"\n",
    "    return \" \".join([stemmer.stem(token) for token in word_tokenize(utterance)])\n",
    "\n",
    "\n",
    "def apply_stemming(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply stemming when there is a language available\n",
    "    \"\"\"\n",
    "    return data.assign(\n",
    "        utt=data.apply(lambda x: stem(get_stemmer(x[\"locale\"]), x[\"utt\"]), axis=1)\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
